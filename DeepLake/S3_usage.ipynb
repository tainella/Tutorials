{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97668e18",
   "metadata": {},
   "source": [
    "### Работа с S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85911c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tainella/opt/anaconda3/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.2.8) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ac6b3",
   "metadata": {},
   "source": [
    "### Загрузка уже существующего датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0c611",
   "metadata": {},
   "source": [
    "На S3 должна лежать папка именно с DeepLake датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df9c610",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetHandlerError",
     "evalue": "A Deep Lake dataset does not exist at the given path (s3://test/fer2013). Check the path provided or in case you want to create a new dataset, use deeplake.empty().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetHandlerError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms3://test/fer2013\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maws_access_key_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mj17EcYUgBVIy11Xh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maws_secret_access_key\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFXXf6iYMPOVXhEuco0CM9aqqzNIN7Xlk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;66;43;03m#'aws_session_token': '123', # Optional\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mendpoint_url\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp://172.16.242.51\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deeplake/api/dataset.py:442\u001b[0m, in \u001b[0;36mdataset.load\u001b[0;34m(path, read_only, memory_cache_size, local_cache_size, creds, token, org_id, verbose, access_method)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_exists(cache_chain):\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetHandlerError(\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA Deep Lake dataset does not exist at the given path (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Check the path provided or in case you want to create a new dataset, use deeplake.empty().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m access_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mDatasetHandlerError\u001b[0m: A Deep Lake dataset does not exist at the given path (s3://test/fer2013). Check the path provided or in case you want to create a new dataset, use deeplake.empty()."
     ]
    }
   ],
   "source": [
    "deeplake.load('s3://test/fer2013', creds = {\n",
    "   'aws_access_key_id': 'abc', \n",
    "   'aws_secret_access_key': 'xyz', \n",
    "   #'aws_session_token': '123', # Optional\n",
    "   'endpoint_url': 'http://localhost:8888'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6c009",
   "metadata": {},
   "source": [
    "Теперь корректный датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a09016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://test/deeplake_fer/deeplake_fer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "ds = deeplake.load('s3://test/deeplake_fer/deeplake_fer', creds = {\n",
    "   'aws_access_key_id': 'abc', \n",
    "   'aws_secret_access_key': 'xyz', \n",
    "   #'aws_session_token': '123', # Optional\n",
    "   'endpoint_url': 'http://localhost:8888'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23642cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='s3://test/deeplake_fer/deeplake_fer', tensors=['images', 'labels'])\n",
      "\n",
      " tensor      htype        shape       dtype  compression\n",
      " -------    -------      -------     -------  ------- \n",
      " images      image     (21, 48, 48)   uint8    jpeg   \n",
      " labels   class_label    (21, 1)     uint32    None   \n"
     ]
    }
   ],
   "source": [
    "ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aaa295",
   "metadata": {},
   "source": [
    "### Добавление датасета в S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8612299",
   "metadata": {},
   "outputs": [],
   "source": [
    "!s3cmd sync {local path to deeplake dataset}  s3://{bucket_name}/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
